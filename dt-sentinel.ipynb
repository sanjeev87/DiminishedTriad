{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import hiredis\n",
    "from redis.sentinel import Sentinel\n",
    "import urllib2\n",
    "import urllib\n",
    "import Queue\n",
    "import hashlib\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def startSentinelListner():\n",
    "    p = REDIS_SENTINEL.pubsub()\n",
    "    channels = ['+sdown','-sdown']\n",
    "    p.psubscribe('*')\n",
    "\n",
    "    for message in p.listen():\n",
    "        handleMessage(message)\n",
    "        \n",
    "dtSentinelInit()\n",
    "startSentinelListner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "REDIS_SENTINEL = None\n",
    "MSG_QUEUE = None\n",
    "NUMBACKUPS = 2\n",
    "HASH_TO_BACK_MAP = None\n",
    "\n",
    "def dtSentinelInit():\n",
    "    global REDIS_SENTINEL\n",
    "    global MSG_QUEUE\n",
    "    global HASH_TO_BACK_MAP\n",
    "    REDIS_SENTINEL = redis.StrictRedis(host='localhost', port=40001)\n",
    "    print REDIS_SENTINEL.sentinel_masters().keys()\n",
    "    HASH_TO_BACK_MAP = {}\n",
    "    updateHashToBackMap()\n",
    "    REDIS_SENTINEL.sentinel_masters()['masterP_30001']['ip']\n",
    "    MSG_QUEUE = Queue.Queue(maxsize=50)\n",
    "\n",
    "    \n",
    "def getKeysInMaster(back):\n",
    "    addr = back.split(\":\")[0]\n",
    "    port = back.split(\":\")[1]\n",
    "    r = redis.StrictRedis(host=addr, port=port, db=0)\n",
    "    return r.keys(\"*\")\n",
    "    \n",
    "def getKeysInRange(source_addr,addr1,addr2):    \n",
    "    # copy keys in range from addr1+1 till addr2 from source_addr\n",
    "    k1, k2 = hash(addr1), hash(addr2)\n",
    "    keys_source_addr = getKeysInMaster(source_addr)\n",
    "    out = []\n",
    "    for key in keys_source_addr:\n",
    "        if k2 > k1: # not crossing the beginning of ring\n",
    "            if hash(key) > k1 and hash(key) <= k2:\n",
    "                out.append(key)\n",
    "        else:\n",
    "            if hash(key) > k1 or (hash(key) >= 0 and hash(key) <= k2):\n",
    "                out.append(key)\n",
    "    return out\n",
    "                \n",
    "def migrateKeys(source_addr,destination_addr,keys):\n",
    "    old_log = getMasterLogs(source_addr)\n",
    "    new_log = \"\"\n",
    "    log_diff = [\"\"]\n",
    "    addr = source_addr.split(\":\")[0]\n",
    "    port = source_addr.split(\":\")[1]\n",
    "    src_r = redis.StrictRedis(host=addr, port=port, db=0)\n",
    "    dst_r = redis.StrictRedis(host=destination_addr.split(\":\")[0], port=destination_addr.split(\":\")[1], db=0)\n",
    "    while len(log_diff)>0:\n",
    "        for key in keys:\n",
    "            try:\n",
    "                print \"Dumping key: %s\" % key\n",
    "                value = src_r.dump(key)\n",
    "                print \"deleting from destination key:\",key\n",
    "                dst_r.delete(key)\n",
    "                print \"Restoring key: %s\" % key\n",
    "                dst_r.restore(key, 0, value)\n",
    "            except Exception,e:\n",
    "                print \"Exception 5:\",e\n",
    "                print \"UNable to migrate key:\",key,\" from addr:\",source_addr,\" to addr:\", destination_addr\n",
    "                continue\n",
    "        new_log = getMasterLogs(source_addr)\n",
    "        log_diff = getLogIncrementalCommands(old_log, new_log)\n",
    "        old_log = new_log\n",
    "        new_keys = []\n",
    "        for i in log_diff:\n",
    "            new_keys.append(i[1])\n",
    "        keys = new_keys\n",
    "    return\n",
    "\n",
    "\n",
    "def getMastersSorted():\n",
    "    keys = sorted(HASH_TO_BACK_MAP.keys())\n",
    "    \n",
    "def hash(key):\n",
    "    return int(hashlib.sha1(key).hexdigest(), 16)\n",
    "\n",
    "def updateHashToBackMap():\n",
    "    ml = getMastersList()\n",
    "    HASH_TO_BACK_MAP.clear()\n",
    "    for m in ml:\n",
    "        HASH_TO_BACK_MAP[hash(m)] = m \n",
    "    print \"HASH_TO_BACK_MAP updated, sorted values:\", sorted(HASH_TO_BACK_MAP.values())\n",
    "    print \"HASH_TO_BACK_MAP updated, MAP :\", HASH_TO_BACK_MAP\n",
    "\n",
    "def getNextNBackends(server_addr, N=NUMBACKUPS):\n",
    "    key = hash(server_addr)\n",
    "    keys = sorted(HASH_TO_BACK_MAP.keys())\n",
    "    index = keys.index(key)\n",
    "    out = []\n",
    "#     for k in keys:\n",
    "#         print k, HASH_TO_BACK_MAP[k]\n",
    "#     print \"hash:\", key, \":\",server_addr\n",
    "#     print \"index:\", index\n",
    "    for i in range(1,N+1):\n",
    "        # we are selecting N backends starting with the backend following the server_addr\n",
    "        # the output list does not contain server_addr\n",
    "        if keys[(index + i)%len(keys)] in HASH_TO_BACK_MAP and HASH_TO_BACK_MAP[keys[(index + i)%len(keys)]] not in out:\n",
    "            out.append(HASH_TO_BACK_MAP[keys[(index + i)%len(keys)]])\n",
    "    print \"getNextNBackends for addr : \",server_addr,\" returning : {\",out,\"}\"\n",
    "    return out\n",
    "\n",
    "def getPrevNBackends(server_addr, N=NUMBACKUPS):\n",
    "    key = hash(server_addr)\n",
    "    keys = sorted(HASH_TO_BACK_MAP.keys())\n",
    "    print \"trying to fins index of key:\",key, \" in hash to back map\"\n",
    "    index = keys.index(key)\n",
    "    out = []\n",
    "    for i in range(1,N+1):\n",
    "        # we are selecting N backends starting with the backend preceeding the server_addr\n",
    "        # the output list does not contain server_addr\n",
    "        if keys[(index - i)%len(keys)] in HASH_TO_BACK_MAP and HASH_TO_BACK_MAP[keys[(index - i)%len(keys)]] not in out:\n",
    "            out.append(HASH_TO_BACK_MAP[keys[(index - i)%len(keys)]])\n",
    "    print \"getPrevNBackends for addr : \",server_addr,\" returning : {\",out,\"}\"\n",
    "    return out\n",
    "\n",
    "def getMastersList():\n",
    "    return [REDIS_SENTINEL.sentinel_masters()[m]['ip'] + ':' + str(REDIS_SENTINEL.sentinel_masters()[m]['port']) for m in REDIS_SENTINEL.sentinel_masters() if not REDIS_SENTINEL.sentinel_masters()[m]['is_sdown']]\n",
    "\n",
    "def sendMasterList(ml = HASH_TO_BACK_MAP.values() if HASH_TO_BACK_MAP else None):\n",
    "    for url in ml:\n",
    "        ip,port = url.split(':')\n",
    "        if port == '30001':\n",
    "            sendListAsPost.('http://'+ip+':'+str(int(port) + 20000), ml)\n",
    "            break\n",
    "\n",
    "def handleJoin(msg):\n",
    "    arr = msg['data'].split(\" \")\n",
    "    new_server_add = arr[2]\n",
    "    new_server_port = arr[3]\n",
    "    print \"migrating data into new server : \", arr\n",
    "    updateHashToBackMap()\n",
    "    hashMapKeys = sorted(HASH_TO_BACK_MAP.keys())\n",
    "    print \"ring sequence\"\n",
    "    for k in hashMapKeys:\n",
    "        print \"addr:\",HASH_TO_BACK_MAP[k] \n",
    "    new_server = new_server_add+\":\"+new_server_port\n",
    "    #get the backend immediately ahead of the node that has joined\n",
    "    next_N = getNextNBackends(new_server,1)\n",
    "    next_back = next_N[0]\n",
    "    \n",
    "    # list to keep track of all our threads\n",
    "    thread_list = []\n",
    "    \n",
    "    #get NUMBACKS + 1 nodes that are immediately behind the node that has just joined\n",
    "    #the prev_backs list is anti clockwise in our ring !!! \n",
    "    prev_backs = getPrevNBackends(new_server,NUMBACKUPS+1)\n",
    "    print \" prev_backs of new server:\",new_server, \" is \", prev_backs\n",
    "    \n",
    "    for i in range(len(prev_backs)-1):\n",
    "        try:\n",
    "    #       keys = getKeysInRange(source_addr,addr1,addr2)\n",
    "            keys = getKeysInRange(prev_backs[i],prev_backs[i+1],prev_backs[i])\n",
    "            print \"obtaining keys:\",keys,\" between :\",prev_backs[i+1] , \" and \", prev_backs[i]\n",
    "    #       migrateKeys(source_addr,destination_addr,keys)\n",
    "            t = threading.Thread(target=migrateKeys, args=(prev_backs[i],new_server,keys))\n",
    "            # Sticks the thread in a list so that it remains accessible\n",
    "            thread_list.append(t)\n",
    "            #migrateKeys(prev_backs[i],new_server,keys)\n",
    "            print \"migrating keys:\",keys,\" between :\",prev_backs[i] , \" and \", new_server\n",
    "        except Exception,e:\n",
    "            print \"UNable to migrate from addr:\",prev_backs[i],\" to addr:\", new_server\n",
    "            print \"Exception:1\",e\n",
    "            continue\n",
    "        \n",
    "    try:\n",
    "        keys = getKeysInRange(next_back,prev_backs[0],new_server)\n",
    "        print \"In handle join getting keys between prev:\",prev_backs[0], \" and new server:\", new_server\n",
    "        t = threading.Thread(target=migrateKeys, args=(next_back,new_server,keys))\n",
    "        # Sticks the thread in a list so that it remains accessible\n",
    "        thread_list.append(t)\n",
    "#         migrateKeys(next_back,new_server,keys)\n",
    "        print \"migrating keys:\",keys,\" between :\",next_back , \" and \", new_server\n",
    "    except Exception,e:\n",
    "            print \"UNable to migrate from addr:\",next_back,\" to addr:\", new_server\n",
    "            print \"Exception:10\",e\n",
    "            \n",
    "    # Starts threads\n",
    "    for thread in thread_list:\n",
    "        thread.start()\n",
    "\n",
    "    # block until all threads terminate\n",
    "    for thread in thread_list:\n",
    "        thread.join()\n",
    "    \n",
    "    sendMasterList(HASH_TO_BACK_MAP.values())\n",
    "        \n",
    "        \n",
    "    \n",
    "def handleLeave(msg):\n",
    "    print 'handleLeave():'#, msg['data']\n",
    "    dead_server_host = msg['data'].split(\" \")[-2]\n",
    "    dead_server_port = msg['data'].split(\" \")[-1]\n",
    "    dead_server = dead_server_host + \":\" + dead_server_port\n",
    "    backs_clockwise = getNextNBackends(dead_server, NUMBACKUPS + 1)\n",
    "    backs_anticlockwise = getPrevNBackends(dead_server, NUMBACKUPS + 1)\n",
    "    print backs_clockwise\n",
    "    print backs_anticlockwise\n",
    "    backs_anticlockwise_len = len(backs_anticlockwise)\n",
    "    print backs_anticlockwise_len\n",
    "    if len(backs_clockwise) != backs_anticlockwise_len:\n",
    "        print \"Error: lengths of previous and next backends do not match\"\n",
    "        return\n",
    "    for i in range(0, backs_anticlockwise_len-1):\n",
    "        keys = getKeysInRange(backs_anticlockwise[i], backs_anticlockwise[i+1], backs_anticlockwise[i])\n",
    "        print keys\n",
    "        migrateKeys(backs_anticlockwise[i], backs_clockwise[backs_anticlockwise_len - 2 - i], keys)\n",
    "        \n",
    "    if backs_anticlockwise_len > 1:\n",
    "        keys = getKeysInRange(backs_clockwise[0], backs_anticlockwise[0], dead_server)\n",
    "        print keys\n",
    "        migrateKeys(backs_clockwise[0], backs_clockwise[backs_anticlockwise_len - 1], keys)\n",
    "    sendMasterList()\n",
    "    \n",
    "def handleMessage(message):\n",
    "    #parseMasterLogs()\n",
    "    t = message['channel']\n",
    "    print message['data'], t\n",
    "    if t == '+sdown':\n",
    "        handleLeave(message)\n",
    "    elif t == '-sdown':\n",
    "        handleJoin(message)\n",
    "    else:\n",
    "#         print \"Unknown channel message:\", message\n",
    "        t = None\n",
    "def sendListAsPost(url, slist):\n",
    "    url = url + '/update_hash_to_back_map?'\n",
    "    print url, slist\n",
    "    s = ''\n",
    "    for i in slist: s = s + ',' + i\n",
    "    s = s[1:]\n",
    "    data = urllib.urlencode({'addrs' : s})\n",
    "#     print 'encoded data', data\n",
    "    response = urllib2.urlopen(url+data)\n",
    "    print \"POST Request:\" + url+data\n",
    "    result = response.read()\n",
    "    return result\n",
    "    \n",
    "def sanitizeString(resp):\n",
    "    resp = resp.replace('\\\"', '')\n",
    "    resp = resp.replace('\\\\n', '\\n')\n",
    "    resp = resp.replace('\\\\r', '\\r')\n",
    "    return resp\n",
    "    \n",
    "def getLogIncrementalCommands(previous_log, new_log):\n",
    "    previous_log = sanitizeString(previous_log)\n",
    "    new_log = sanitizeString(new_log)\n",
    "    resp = new_log.replace(previous_log, \"\")\n",
    "    try:\n",
    "        reader = hiredis.Reader()\n",
    "        resp = resp.replace('\\\"', '')\n",
    "        resp = resp.replace('\\\\n', '\\n')\n",
    "        resp = resp.replace('\\\\r', '\\r')\n",
    "        reader.feed(resp)\n",
    "        log_list = []\n",
    "        l = reader.gets()\n",
    "        while l!=False:\n",
    "            log_list.append(l)\n",
    "            print l\n",
    "            l = reader.gets()\n",
    "        return log_list\n",
    "    except Exception, e:\n",
    "        print e\n",
    "        return []\n",
    "        \n",
    "def getMasterLogs(address):\n",
    "    print \"Getting logs for :\", address\n",
    "    try:\n",
    "        url = '/getAOFLog'\n",
    "        port = str((int)(address.split(':')[1])+20000)\n",
    "        req = 'http://'+address.split(':')[0]+':'+port\n",
    "        print req+url\n",
    "        response = urllib2.urlopen(req+url)\n",
    "        return str(response.read())\n",
    "    except Exception, e:\n",
    "        print e\n",
    "        return \"\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
